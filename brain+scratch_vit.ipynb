{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-23T19:22:07.838947Z",
     "iopub.status.busy": "2024-01-23T19:22:07.838564Z",
     "iopub.status.idle": "2024-01-23T19:22:12.952250Z",
     "shell.execute_reply": "2024-01-23T19:22:12.951244Z",
     "shell.execute_reply.started": "2024-01-23T19:22:07.838914Z"
    },
    "id": "Xi2pjXPprRkB",
    "papermill": {
     "duration": 6.04489,
     "end_time": "2024-01-11T06:49:55.049446",
     "exception": false,
     "start_time": "2024-01-11T06:49:49.004556",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.nn import functional as F\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torchvision.transforms import Lambda\n",
    "import torch.multiprocessing as mp\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T19:22:12.954774Z",
     "iopub.status.busy": "2024-01-23T19:22:12.954295Z",
     "iopub.status.idle": "2024-01-23T19:22:12.991491Z",
     "shell.execute_reply": "2024-01-23T19:22:12.990253Z",
     "shell.execute_reply.started": "2024-01-23T19:22:12.954743Z"
    },
    "papermill": {
     "duration": 0.040316,
     "end_time": "2024-01-11T06:49:55.093817",
     "exception": false,
     "start_time": "2024-01-11T06:49:55.053501",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SwishActivation(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "class PatchEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.image_size = config[\"image_size\"]\n",
    "        self.patch_size = config[\"patch_size\"]\n",
    "        self.num_channels = config[\"num_channels\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_patches = (self.image_size // self.patch_size) ** 2\n",
    "        self.projection = nn.Conv2d(self.num_channels, self.hidden_size, kernel_size=self.patch_size, stride=self.patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.patch_embeddings = PatchEmbeddings(config)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, config[\"hidden_size\"]))\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(1, self.patch_embeddings.num_patches, config[\"hidden_size\"]))\n",
    "        self.dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embeddings(x)\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
    "        position_embeddings = self.position_embeddings[:, :seq_len, :]  # Adjust size\n",
    "\n",
    "        # Adding position_embeddings without using expand\n",
    "        x = torch.cat((cls_tokens, x + position_embeddings), dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, hidden_size, attention_head_size, dropout, bias=True):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_head_size = attention_head_size\n",
    "        self.query = nn.Linear(hidden_size, attention_head_size, bias=bias)\n",
    "        self.key = nn.Linear(hidden_size, attention_head_size, bias=bias)\n",
    "        self.value = nn.Linear(hidden_size, attention_head_size, bias=bias)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "        attention_scores = torch.matmul(query, key.transpose(-1, -2))\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        attention_probs = F.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "        attention_output = torch.matmul(attention_probs, value)\n",
    "        return attention_output, attention_probs\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_attention_heads = config[\"num_attention_heads\"]\n",
    "        self.attention_head_size = self.hidden_size // self.num_attention_heads\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "        self.qkv_bias = config[\"qkv_bias\"]\n",
    "        self.heads = nn.ModuleList([AttentionHead(\n",
    "            self.hidden_size,\n",
    "            self.attention_head_size,\n",
    "            config[\"attention_probs_dropout_prob\"],\n",
    "            self.qkv_bias\n",
    "        ) for _ in range(self.num_attention_heads)])\n",
    "        self.output_projection = nn.Linear(self.all_head_size, self.hidden_size)\n",
    "        self.output_dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        attention_outputs = [head(x) for head in self.heads]\n",
    "        attention_output = torch.cat([output for output, _ in attention_outputs], dim=-1)\n",
    "        attention_output = self.output_projection(attention_output)\n",
    "        attention_output = self.output_dropout(attention_output)\n",
    "        if not output_attentions:\n",
    "            return attention_output, None\n",
    "        else:\n",
    "            attention_probs = torch.stack([attention_probs for _, attention_probs in attention_outputs], dim=1)\n",
    "            return attention_output, attention_probs\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.dense_1 = nn.Linear(config[\"hidden_size\"], config[\"intermediate_size\"])\n",
    "        self.activation = SwishActivation()\n",
    "        self.dense_2 = nn.Linear(config[\"intermediate_size\"], config[\"hidden_size\"])\n",
    "        self.dropout = nn.Dropout(config[\"hidden_dropout_prob\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.use_faster_attention = config.get(\"use_faster_attention\", False)\n",
    "        if self.use_faster_attention:\n",
    "            self.attention = FasterMultiHeadAttention(config)\n",
    "        else:\n",
    "            self.attention = MultiHeadAttention(config)\n",
    "        self.layer_norm_1 = nn.LayerNorm(config[\"hidden_size\"])\n",
    "        self.mlp = MLP(config)\n",
    "        self.layer_norm_2 = nn.LayerNorm(config[\"hidden_size\"])\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        attention_output, attention_probs = self.attention(self.layer_norm_1(x), output_attentions=output_attentions)\n",
    "        x = x + attention_output\n",
    "        mlp_output = self.mlp(self.layer_norm_2(x))\n",
    "        x = x + mlp_output\n",
    "        if not output_attentions:\n",
    "            return x, None\n",
    "        else:\n",
    "            return x, attention_probs\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(config) for _ in range(config[\"num_hidden_layers\"])])\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        all_attentions = []\n",
    "        for block in self.blocks:\n",
    "            x, attention_probs = block(x, output_attentions=output_attentions)\n",
    "            if output_attentions:\n",
    "                all_attentions.append(attention_probs)\n",
    "        if not output_attentions:\n",
    "            return x, None\n",
    "        else:\n",
    "            return x, all_attentions\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.image_size = config[\"image_size\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_classes = config[\"num_classes\"]\n",
    "        self.embedding = EmbeddingLayer(config)\n",
    "        self.encoder = TransformerEncoder(config)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.num_classes)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x, output_attentions=False):\n",
    "        embedding_output = self.embedding(x)\n",
    "        encoder_output, all_attentions = self.encoder(embedding_output, output_attentions=output_attentions)\n",
    "        logits = self.classifier(encoder_output[:, 0, :])\n",
    "        if not output_attentions:\n",
    "            return logits, None\n",
    "        else:\n",
    "            return logits, all_attentions\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, (nn.Linear, nn.Conv2d)):\n",
    "            nn.init.xavier_uniform_(module.weight.data)\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-23T19:31:28.603629Z",
     "iopub.status.busy": "2024-01-23T19:31:28.602737Z",
     "iopub.status.idle": "2024-01-23T19:31:28.612364Z",
     "shell.execute_reply": "2024-01-23T19:31:28.611234Z",
     "shell.execute_reply.started": "2024-01-23T19:31:28.603567Z"
    },
    "id": "UbEp406Wqksp",
    "papermill": {
     "duration": 0.013195,
     "end_time": "2024-01-11T06:49:55.110485",
     "exception": false,
     "start_time": "2024-01-11T06:49:55.097290",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(batch_size=64):\n",
    "    dataset_path = \"/kaggle/input/brain-tumor/brain\"\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    train_dataset = ImageFolder(root=os.path.join(dataset_path, 'Training'), transform=transform)\n",
    "    test_dataset = ImageFolder(root=os.path.join(dataset_path, 'Testing'), transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-23T19:31:28.828419Z",
     "iopub.status.busy": "2024-01-23T19:31:28.827752Z",
     "iopub.status.idle": "2024-01-23T19:31:28.840976Z",
     "shell.execute_reply": "2024-01-23T19:31:28.839961Z",
     "shell.execute_reply.started": "2024-01-23T19:31:28.828387Z"
    },
    "id": "djY52Edqug3M",
    "papermill": {
     "duration": 0.018563,
     "end_time": "2024-01-11T06:49:55.132441",
     "exception": false,
     "start_time": "2024-01-11T06:49:55.113878",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return total_loss / len(test_loader), correct / total\n",
    "\n",
    "def plot_training_progress(train_losses, train_accuracies, test_losses, test_accuracies):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(test_losses, label=\"Test\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label=\"Train\")\n",
    "    plt.plot(test_accuracies, label=\"Test\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T19:31:28.982138Z",
     "iopub.status.busy": "2024-01-23T19:31:28.981762Z",
     "iopub.status.idle": "2024-01-23T19:31:28.989273Z",
     "shell.execute_reply": "2024-01-23T19:31:28.988368Z",
     "shell.execute_reply.started": "2024-01-23T19:31:28.982111Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize some sample images from the dataset\n",
    "def visualize_samples(dataset_loader, num_samples=5):\n",
    "    data_iter = iter(dataset_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    class_names = dataset_loader.dataset.classes\n",
    "\n",
    "    print(f\"Class Names: {class_names}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        image = images[i].numpy().transpose((1, 2, 0))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Class: {class_names[labels[i]]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-23T19:31:29.168522Z",
     "iopub.status.busy": "2024-01-23T19:31:29.168149Z",
     "iopub.status.idle": "2024-01-23T19:31:29.174294Z",
     "shell.execute_reply": "2024-01-23T19:31:29.173167Z",
     "shell.execute_reply.started": "2024-01-23T19:31:29.168493Z"
    },
    "id": "qGHq-Nl0rrFF",
    "papermill": {
     "duration": 0.011711,
     "end_time": "2024-01-11T06:49:55.147926",
     "exception": false,
     "start_time": "2024-01-11T06:49:55.136215",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration for the Vision Transformer\n",
    "config = {\n",
    "    \"image_size\": 64,\n",
    "    \"patch_size\": 4,\n",
    "    \"num_channels\": 3,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_hidden_layers\": 16,\n",
    "    \"num_attention_heads\": 32,\n",
    "    \"intermediate_size\": 64,\n",
    "    \"hidden_dropout_prob\": 0.1,\n",
    "    \"attention_probs_dropout_prob\": 0.1,\n",
    "    \"qkv_bias\": True,\n",
    "    \"num_classes\": 10,\n",
    "    \"initializer_range\": 0.02,\n",
    "    \"use_faster_attention\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T19:58:35.049440Z",
     "iopub.status.busy": "2024-01-23T19:58:35.049069Z",
     "iopub.status.idle": "2024-01-23T19:58:35.053993Z",
     "shell.execute_reply": "2024-01-23T19:58:35.053039Z",
     "shell.execute_reply.started": "2024-01-23T19:58:35.049404Z"
    },
    "papermill": {
     "duration": 0.010146,
     "end_time": "2024-01-11T06:49:55.161736",
     "exception": false,
     "start_time": "2024-01-11T06:49:55.151590",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-23T19:58:35.311469Z",
     "iopub.status.busy": "2024-01-23T19:58:35.311130Z",
     "iopub.status.idle": "2024-01-23T19:58:35.635033Z",
     "shell.execute_reply": "2024-01-23T19:58:35.634092Z",
     "shell.execute_reply.started": "2024-01-23T19:58:35.311439Z"
    },
    "id": "nJdJTQrIvAat",
    "outputId": "a6d17313-d7a7-4f43-ae06-5cd59b0b1545",
    "papermill": {
     "duration": 6.999079,
     "end_time": "2024-01-11T06:50:02.164298",
     "exception": false,
     "start_time": "2024-01-11T06:49:55.165219",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize and move model to device\n",
    "model = VisionTransformer(config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T19:58:35.637038Z",
     "iopub.status.busy": "2024-01-23T19:58:35.636667Z",
     "iopub.status.idle": "2024-01-23T19:58:35.656867Z",
     "shell.execute_reply": "2024-01-23T19:58:35.656041Z",
     "shell.execute_reply.started": "2024-01-23T19:58:35.637006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print model's architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T19:58:35.932952Z",
     "iopub.status.busy": "2024-01-23T19:58:35.932563Z",
     "iopub.status.idle": "2024-01-23T19:58:35.955095Z",
     "shell.execute_reply": "2024-01-23T19:58:35.954097Z",
     "shell.execute_reply.started": "2024-01-23T19:58:35.932922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lists to store training and testing metrics for visualization\n",
    "train_losses, train_accuracies = [], []\n",
    "test_losses, test_accuracies = [], []\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T19:58:36.498235Z",
     "iopub.status.busy": "2024-01-23T19:58:36.497474Z",
     "iopub.status.idle": "2024-01-23T19:58:38.463910Z",
     "shell.execute_reply": "2024-01-23T19:58:38.463039Z",
     "shell.execute_reply.started": "2024-01-23T19:58:36.498197Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_loader, test_loader = load_data(batch_size=batch_size)\n",
    "\n",
    "# Visualize some sample images from the dataset\n",
    "visualize_samples(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2024-01-23T19:58:39.906053Z",
     "iopub.status.busy": "2024-01-23T19:58:39.905659Z",
     "iopub.status.idle": "2024-01-23T20:06:06.148368Z",
     "shell.execute_reply": "2024-01-23T20:06:06.146931Z",
     "shell.execute_reply.started": "2024-01-23T19:58:39.906009Z"
    },
    "id": "UTuHlgNgzfWW",
    "outputId": "91986773-c932-40b4-835b-ef78f7151fa3",
    "papermill": {
     "duration": 7222.443248,
     "end_time": "2024-01-11T08:50:24.611475",
     "exception": false,
     "start_time": "2024-01-11T06:50:02.168227",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    train_loss, train_accuracy = train(model, train_loader, optimizer, criterion, device)\n",
    "\n",
    "    # Testing phase\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    # Print details\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Learning Rate: {scheduler.get_last_lr()[0]:.8f}, \"\n",
    "    f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "    f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Store metrics for visualization\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    scheduler.step()  # Adjust learning rate after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.status.busy": "2024-01-23T20:06:06.149175Z",
     "iopub.status.idle": "2024-01-23T20:06:06.149549Z",
     "shell.execute_reply": "2024-01-23T20:06:06.149385Z",
     "shell.execute_reply.started": "2024-01-23T20:06:06.149366Z"
    },
    "id": "xFiXAL9BzvTV",
    "outputId": "2bf0783b-9468-4f4c-b271-48e0eeb26bae",
    "papermill": {
     "duration": 0.701142,
     "end_time": "2024-01-11T08:50:25.320450",
     "exception": false,
     "start_time": "2024-01-11T08:50:24.619308",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training progress\n",
    "plot_training_progress(train_losses, train_accuracies, test_losses, test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMslFzruD1HVyaDuYOXSsKW",
   "gpuType": "V100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4278522,
     "sourceId": 7364918,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7241.848712,
   "end_time": "2024-01-11T08:50:27.267148",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-11T06:49:45.418436",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
